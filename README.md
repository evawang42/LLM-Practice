# LLM-Practice
## Task 1 - Streaming chat with Ollama (Python, Async)
This task implements a minimal **async streaming** chat function.

`config.py` example:
```py
OLLAMA_URL = "http://127.0.0.1:11434"
```
## Task 2 - Write prompts
This task implements a minimal **Q&A over documents**.

## Reference
- https://github.com/ollama/ollama-python